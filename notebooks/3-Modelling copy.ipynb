{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cfbb4b6",
   "metadata": {},
   "source": [
    "# Modelisation\n",
    "## Auteur Linda MARTIN\n",
    "\n",
    "Aprés la restructuration des données, on peut étudier les différents metaparamètres des modéles utilisables pour effectuer l'apprentissage des données. Comme nos données sont en fonction du temps, elles ne peuvent pas être mélangées. Pour ce type de problème,  les modèles sont de type RNN (réseau neuronal récurrent) car l'apprentissage se fait par séquence de temps et la sortie doit restituer cette séquence. Les 2 modèles que je vais expérimenter sont GRU (Gated Recurrent Unit) et LSTM (Long Short Term Memory) qui drivent de RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a73bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import pathlib as pl\n",
    "from typing import Tuple\n",
    "from typing import List\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2a13d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data_path: str=\"../data/\"):\n",
    "        self.datapath = data_path\n",
    "        self.train_path = pl.Path(data_path) / \"train.csv\"\n",
    "        self.test_path = pl.Path(data_path) / \"test.csv\"\n",
    "        self.train_labels_path = pl.Path(data_path) / \"train_labels.csv\"\n",
    "        self.target_pairs_path = pl.Path(data_path) / \"target_pairs.csv\"\n",
    "        \n",
    "    def load_data(self) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "        train_df = pd.read_csv(self.train_path, index_col='date_id')\n",
    "        test_df = pd.read_csv(self.test_path, index_col='date_id')\n",
    "        train_labels_df = pd.read_csv(self.train_labels_path, index_col='date_id')\n",
    "        target_pairs_df = pd.read_csv(self.target_pairs_path)\n",
    "        return train_df, test_df, train_labels_df, target_pairs_df\n",
    "\n",
    "class PreProcess:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_train_info(self, df):\n",
    "        \"\"\" Construction d'une data des entêtes de colonnes.\n",
    "        Args:\n",
    "            df (pd.DataFrame): Input dataframe d'entrainement.\n",
    "        Returns:\n",
    "            pd.DataFrame: Détail des informations de chaque colonne.\n",
    "        \"\"\"\n",
    "        df_names = df.columns\n",
    "        # Fonction pour nettoyer et split les noms\n",
    "        def clean_and_split(name):\n",
    "            name = name.replace(\"open_interest\", \"open interest\")\n",
    "            name = name.replace(\"settlement_price\", \"settlement price\")\n",
    "            name = name.replace(\"US_Stock\", \"US Stock\")\n",
    "            name = name.replace(\"adj_close\", \"Close\")\n",
    "            name = name.replace(\"adj_\", \"adjusted \")\n",
    "            name = name.replace(\"-\", \"_\")\n",
    "            return name.split(\"_\")\n",
    "\n",
    "        # Création du DataFrame d'infos\n",
    "        df_info = pd.DataFrame(\n",
    "            {\n",
    "            'Column': df_names,\n",
    "            'Split': [clean_and_split(name) for name in df_names]\n",
    "        })\n",
    "\n",
    "        df_info['Category'] = df_info['Split'].apply(lambda x: x[0])    \n",
    "        df_info['Ticker'] = df_info['Split'].apply(\n",
    "        lambda x: \"_\".join(x[1:-1]) if len(x) > 2 else x[-1] if len(x) == 2 else \"\"\n",
    "        )\n",
    "        df_info['Type'] = df_info['Split'].apply(lambda x: x[-1])\n",
    "\n",
    "        # Nettoyage final\n",
    "        df_info['Ticker'] = df_info.apply(\n",
    "            lambda row: row['Type'] if row['Ticker'] == \"\" else row['Ticker'], axis=1\n",
    "        )\n",
    "        df_info['Column_Id'] = df_info.index + 1\n",
    "\n",
    "        # Sélection des colonnes finales\n",
    "        df_info = df_info[['Column_Id', 'Column', 'Category', 'Ticker', 'Type']]    \n",
    "        return df_info\n",
    "    \n",
    "    def get_preprocess_data(self, df, cond):\n",
    "        # Fonction pour obtenir les données prétraitées en fonction de la condition\n",
    "        if cond.Column.size > 0:\n",
    "            return df[cond.Column.values[0]]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def preprocess(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df_processed = df.copy()\n",
    "        df_processed = df_processed.drop(columns=['is_score'], errors='ignore')\n",
    "        df_info = self.get_train_info(df_processed)\n",
    "\n",
    "\n",
    "        df_processed.reset_index(inplace=True)\n",
    "        # On renomme la date_id en date\n",
    "        df_processed = df_processed.rename({'date_id': 'date'}, axis='columns')\n",
    "        # Initialisation du DataFrame résultat\n",
    "        result = pd.DataFrame(columns=['date', 'id', 'close', 'open', 'high', 'low', 'volume', 'sprice', 'interest'])\n",
    "        \n",
    "        for  Category  in df_info.groupby('Category').groups.keys():\n",
    "            txtCategory=Category.replace(' ','_')\n",
    "            for label in df_info[(df_info.Category==Category)].groupby('Ticker').groups.keys():\n",
    "                temp_df = pd.DataFrame()\n",
    "                temp_df['date'] = df_processed['date']\n",
    "                temp_df['id'] = f'{txtCategory}_{label}'\n",
    "\n",
    "                if Category in ['FX','LME']:\n",
    "                    temp_df['close'] = df_processed[df_info[(df_info.Category==Category) & (df_info.Ticker==label)].Column.values[0]]\n",
    "                    temp_df['open'] = None\n",
    "                    temp_df['high'] = None\n",
    "                    temp_df['low'] = None\n",
    "                    temp_df['volume'] = None\n",
    "                    temp_df['sprice'] = None\n",
    "                    temp_df['interest'] = None\n",
    "                else:\n",
    "                    temp_df['close'] = self.get_preprocess_data(df_processed,df_info[(df_info.Category==Category) & (df_info.Ticker==label) & (df_info.Type.isin(['Close', 'adjusted close']))])\n",
    "                    temp_df['open'] = self.get_preprocess_data(df_processed,df_info[(df_info.Category==Category) & (df_info.Ticker==label) & (df_info.Type.isin(['Open','adjusted open']))])\n",
    "                    temp_df['high'] = self.get_preprocess_data(df_processed,df_info[(df_info.Category==Category) & (df_info.Ticker==label) & (df_info.Type.isin(['High','adjusted high']))])\n",
    "                    temp_df['low'] = self.get_preprocess_data(df_processed,df_info[(df_info.Category==Category) & (df_info.Ticker==label) & (df_info.Type.isin(['Low','adjusted low']))])\n",
    "                    temp_df['volume'] = self.get_preprocess_data(df_processed,df_info[(df_info.Category==Category) & (df_info.Ticker==label) & (df_info.Type.isin(['Volume', 'adjusted volume']))])\n",
    "                    temp_df['sprice'] = self.get_preprocess_data(df_processed,df_info[(df_info.Category==Category) & (df_info.Ticker==label) & (df_info.Type.isin(['settlement price','adjusted settlement price']))])\n",
    "                    temp_df['interest'] = self.get_preprocess_data(df_processed,df_info[(df_info.Category==Category) & (df_info.Ticker==label) & (df_info.Type.isin(['open interest','adjusted open interest']))])\n",
    "                result = pd.concat([result, temp_df], ignore_index=True)\n",
    "        \n",
    "        # Réinitialiser l'index\n",
    "        result = result.reset_index(drop=True)\n",
    "        \n",
    "        # Trier par date et id \n",
    "        result = result.sort_values(['date', 'id']).reset_index(drop=True)\n",
    "        \n",
    "        return result  \n",
    "    \n",
    "class FeatureEngineer:\n",
    "    \"\"\"Class to handle feature engineering\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def add_lag_features(self,\n",
    "        df: pd.DataFrame, \n",
    "        lags: List[int], \n",
    "        date_col: str = 'date'\n",
    "        ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Add lag features for specified columns and lags.\n",
    "        \"\"\"\n",
    "        df = df.sort_values(date_col)\n",
    "        cols = set(df.columns)\n",
    "        cols.remove('id')\n",
    "        cols.remove('date')\n",
    "        for col in cols:\n",
    "            for lag in lags:\n",
    "                df[f'{col}_lag{lag}'] = df.groupby('id')[col].shift(lag)\n",
    "        return df\n",
    "    \n",
    "    def add_rolling_features(self,\n",
    "        df: pd.DataFrame,\n",
    "        windows: List[int],\n",
    "        date_col: str = 'date') -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "        Add rolling mean and std features for specified columns and windows.\n",
    "        \"\"\"\n",
    "        df = df.sort_values(date_col)\n",
    "        cols = set(df.columns)\n",
    "        cols.remove('id')\n",
    "        cols.remove('date')\n",
    "        for col in cols:\n",
    "            for window in windows:\n",
    "                df[f'{col}_rollmean{window}'] = df.groupby('id')[col].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "                df[f'{col}_rollstd{window}'] = df.groupby('id')[col].transform(lambda x: x.rolling(window, min_periods=1).std())\n",
    "                df[f'{col}_rollmin{window}'] = df.groupby('id')[col].transform(lambda x: x.rolling(window, min_periods=1).min())\n",
    "                df[f'{col}_rollmax{window}'] = df.groupby('id')[col].transform(lambda x: x.rolling(window, min_periods=1).max())\n",
    "        return df\n",
    "    \n",
    "    def prepare_features(self, train_df, test_df):\n",
    "        \"\"\"Engineer features for training and testing data\"\"\"\n",
    "        try:\n",
    "            # Combine train and test for feature engineering\n",
    "            train_cols = set(train_df.columns)\n",
    "            test_cols = set(test_df.columns)\n",
    "            common_cols = train_cols.intersection(test_cols)\n",
    "            combined_data = pd.concat([\n",
    "                train_df[list(common_cols)],\n",
    "                test_df[list(common_cols)]\n",
    "            ], axis=0).reset_index(drop=True)\n",
    "            \n",
    "            combined_data = train_df.merge(\n",
    "                test_df,\n",
    "                on='date',\n",
    "                how='inner',   # ou 'left'\n",
    "                suffixes=('_t2', '_t1')\n",
    "            )\n",
    "\n",
    "            combined_data = self.add_lag_features(combined_data, lags=[1, 2, 3, 5, 7])\n",
    "            \n",
    "            # Add rolling features\n",
    "            combined_data = self.add_rolling_features(combined_data, windows=[5, 10, 15])\n",
    "            # Handle missing values\n",
    "            combined_data = combined_data.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "\n",
    "            # Split back to train and test\n",
    "            train_size = len(train_df)\n",
    "            train_features = combined_data.iloc[:train_size]\n",
    "            test_features = combined_data.iloc[train_size:]\n",
    "\n",
    "            return train_features, test_features\n",
    "        except Exception as e:\n",
    "            print(f\"Feature preparation failed: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7950d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class FeatureTarget:\n",
    "    \"\"\"Class to handle target feature engineering\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def prepare_targets(self, train_labels_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Prepare target information from pairs DataFrame.\n",
    "        Args:\n",
    "            pairs (pd.DataFrame): DataFrame containing 'pair' column.   \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with target information including price_1, price_2, and is_pair.\n",
    "        \"\"\"\n",
    "        target_cols = [col for col in train_labels_df.columns if col not in ['timestamp', 'id']]\n",
    "        display(target_cols)\n",
    "        target_values = train_labels_df[target_cols].values\n",
    "        return target_values, target_cols\n",
    "    \n",
    "    def prepare_targets_info(self, pairs: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Prepare target information from pairs DataFrame.\n",
    "        Args:\n",
    "            pairs (pd.DataFrame): DataFrame containing 'pair' column.\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with target information including price_1, price_2, and is_pair.\n",
    "        \"\"\"\n",
    "\n",
    "        target_definitions = pairs[\"pair\"].str.split(\" - \", expand=True)\n",
    "        target_info = pairs.copy()\n",
    "\n",
    "        # Colonnes price_1 et price_2 (équivalent aux colonnes [,1] et [,2])\n",
    "        target_info[\"price_1\"] = target_definitions[0]\n",
    "        target_info[\"price_2\"] = target_definitions[1]\n",
    "\n",
    "        # is.pair = second élément non vide\n",
    "        target_info['is_pair'] = target_info['price_2'].apply(lambda x:x is not None)\n",
    "\n",
    "        # Retirer la colonne \"pair\"\n",
    "        target_info = target_info.drop(columns=[\"pair\"])\n",
    "        return target_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c7b7eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = DataLoader()\n",
    "featureTarget = FeatureTarget()\n",
    "featureEngineer = FeatureEngineer()\n",
    "preProcess = PreProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8cfcccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, train_labels_df, target_pairs_df = dataLoader.load_data()\n",
    "train_df_process = preProcess.preprocess(train_df)\n",
    "test_df_process = preProcess.preprocess(test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "28575f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1917"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_cols = set(train_df.columns)\n",
    "test_cols = set(test_df.columns)\n",
    "common_cols = train_cols.intersection(test_cols)\n",
    "combined_data = pd.concat([\n",
    "                train_df[list(common_cols)],\n",
    "                test_df[list(common_cols)]\n",
    "            ], axis=0).reset_index(drop=True)\n",
    "display(len(combined_data))\n",
    "train_size = len(train_df)\n",
    "train_features = combined_data.iloc[:train_size]\n",
    "display(len(train_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b433c9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_0',\n",
       " 'target_1',\n",
       " 'target_2',\n",
       " 'target_3',\n",
       " 'target_4',\n",
       " 'target_5',\n",
       " 'target_6',\n",
       " 'target_7',\n",
       " 'target_8',\n",
       " 'target_9',\n",
       " 'target_10',\n",
       " 'target_11',\n",
       " 'target_12',\n",
       " 'target_13',\n",
       " 'target_14',\n",
       " 'target_15',\n",
       " 'target_16',\n",
       " 'target_17',\n",
       " 'target_18',\n",
       " 'target_19',\n",
       " 'target_20',\n",
       " 'target_21',\n",
       " 'target_22',\n",
       " 'target_23',\n",
       " 'target_24',\n",
       " 'target_25',\n",
       " 'target_26',\n",
       " 'target_27',\n",
       " 'target_28',\n",
       " 'target_29',\n",
       " 'target_30',\n",
       " 'target_31',\n",
       " 'target_32',\n",
       " 'target_33',\n",
       " 'target_34',\n",
       " 'target_35',\n",
       " 'target_36',\n",
       " 'target_37',\n",
       " 'target_38',\n",
       " 'target_39',\n",
       " 'target_40',\n",
       " 'target_41',\n",
       " 'target_42',\n",
       " 'target_43',\n",
       " 'target_44',\n",
       " 'target_45',\n",
       " 'target_46',\n",
       " 'target_47',\n",
       " 'target_48',\n",
       " 'target_49',\n",
       " 'target_50',\n",
       " 'target_51',\n",
       " 'target_52',\n",
       " 'target_53',\n",
       " 'target_54',\n",
       " 'target_55',\n",
       " 'target_56',\n",
       " 'target_57',\n",
       " 'target_58',\n",
       " 'target_59',\n",
       " 'target_60',\n",
       " 'target_61',\n",
       " 'target_62',\n",
       " 'target_63',\n",
       " 'target_64',\n",
       " 'target_65',\n",
       " 'target_66',\n",
       " 'target_67',\n",
       " 'target_68',\n",
       " 'target_69',\n",
       " 'target_70',\n",
       " 'target_71',\n",
       " 'target_72',\n",
       " 'target_73',\n",
       " 'target_74',\n",
       " 'target_75',\n",
       " 'target_76',\n",
       " 'target_77',\n",
       " 'target_78',\n",
       " 'target_79',\n",
       " 'target_80',\n",
       " 'target_81',\n",
       " 'target_82',\n",
       " 'target_83',\n",
       " 'target_84',\n",
       " 'target_85',\n",
       " 'target_86',\n",
       " 'target_87',\n",
       " 'target_88',\n",
       " 'target_89',\n",
       " 'target_90',\n",
       " 'target_91',\n",
       " 'target_92',\n",
       " 'target_93',\n",
       " 'target_94',\n",
       " 'target_95',\n",
       " 'target_96',\n",
       " 'target_97',\n",
       " 'target_98',\n",
       " 'target_99',\n",
       " 'target_100',\n",
       " 'target_101',\n",
       " 'target_102',\n",
       " 'target_103',\n",
       " 'target_104',\n",
       " 'target_105',\n",
       " 'target_106',\n",
       " 'target_107',\n",
       " 'target_108',\n",
       " 'target_109',\n",
       " 'target_110',\n",
       " 'target_111',\n",
       " 'target_112',\n",
       " 'target_113',\n",
       " 'target_114',\n",
       " 'target_115',\n",
       " 'target_116',\n",
       " 'target_117',\n",
       " 'target_118',\n",
       " 'target_119',\n",
       " 'target_120',\n",
       " 'target_121',\n",
       " 'target_122',\n",
       " 'target_123',\n",
       " 'target_124',\n",
       " 'target_125',\n",
       " 'target_126',\n",
       " 'target_127',\n",
       " 'target_128',\n",
       " 'target_129',\n",
       " 'target_130',\n",
       " 'target_131',\n",
       " 'target_132',\n",
       " 'target_133',\n",
       " 'target_134',\n",
       " 'target_135',\n",
       " 'target_136',\n",
       " 'target_137',\n",
       " 'target_138',\n",
       " 'target_139',\n",
       " 'target_140',\n",
       " 'target_141',\n",
       " 'target_142',\n",
       " 'target_143',\n",
       " 'target_144',\n",
       " 'target_145',\n",
       " 'target_146',\n",
       " 'target_147',\n",
       " 'target_148',\n",
       " 'target_149',\n",
       " 'target_150',\n",
       " 'target_151',\n",
       " 'target_152',\n",
       " 'target_153',\n",
       " 'target_154',\n",
       " 'target_155',\n",
       " 'target_156',\n",
       " 'target_157',\n",
       " 'target_158',\n",
       " 'target_159',\n",
       " 'target_160',\n",
       " 'target_161',\n",
       " 'target_162',\n",
       " 'target_163',\n",
       " 'target_164',\n",
       " 'target_165',\n",
       " 'target_166',\n",
       " 'target_167',\n",
       " 'target_168',\n",
       " 'target_169',\n",
       " 'target_170',\n",
       " 'target_171',\n",
       " 'target_172',\n",
       " 'target_173',\n",
       " 'target_174',\n",
       " 'target_175',\n",
       " 'target_176',\n",
       " 'target_177',\n",
       " 'target_178',\n",
       " 'target_179',\n",
       " 'target_180',\n",
       " 'target_181',\n",
       " 'target_182',\n",
       " 'target_183',\n",
       " 'target_184',\n",
       " 'target_185',\n",
       " 'target_186',\n",
       " 'target_187',\n",
       " 'target_188',\n",
       " 'target_189',\n",
       " 'target_190',\n",
       " 'target_191',\n",
       " 'target_192',\n",
       " 'target_193',\n",
       " 'target_194',\n",
       " 'target_195',\n",
       " 'target_196',\n",
       " 'target_197',\n",
       " 'target_198',\n",
       " 'target_199',\n",
       " 'target_200',\n",
       " 'target_201',\n",
       " 'target_202',\n",
       " 'target_203',\n",
       " 'target_204',\n",
       " 'target_205',\n",
       " 'target_206',\n",
       " 'target_207',\n",
       " 'target_208',\n",
       " 'target_209',\n",
       " 'target_210',\n",
       " 'target_211',\n",
       " 'target_212',\n",
       " 'target_213',\n",
       " 'target_214',\n",
       " 'target_215',\n",
       " 'target_216',\n",
       " 'target_217',\n",
       " 'target_218',\n",
       " 'target_219',\n",
       " 'target_220',\n",
       " 'target_221',\n",
       " 'target_222',\n",
       " 'target_223',\n",
       " 'target_224',\n",
       " 'target_225',\n",
       " 'target_226',\n",
       " 'target_227',\n",
       " 'target_228',\n",
       " 'target_229',\n",
       " 'target_230',\n",
       " 'target_231',\n",
       " 'target_232',\n",
       " 'target_233',\n",
       " 'target_234',\n",
       " 'target_235',\n",
       " 'target_236',\n",
       " 'target_237',\n",
       " 'target_238',\n",
       " 'target_239',\n",
       " 'target_240',\n",
       " 'target_241',\n",
       " 'target_242',\n",
       " 'target_243',\n",
       " 'target_244',\n",
       " 'target_245',\n",
       " 'target_246',\n",
       " 'target_247',\n",
       " 'target_248',\n",
       " 'target_249',\n",
       " 'target_250',\n",
       " 'target_251',\n",
       " 'target_252',\n",
       " 'target_253',\n",
       " 'target_254',\n",
       " 'target_255',\n",
       " 'target_256',\n",
       " 'target_257',\n",
       " 'target_258',\n",
       " 'target_259',\n",
       " 'target_260',\n",
       " 'target_261',\n",
       " 'target_262',\n",
       " 'target_263',\n",
       " 'target_264',\n",
       " 'target_265',\n",
       " 'target_266',\n",
       " 'target_267',\n",
       " 'target_268',\n",
       " 'target_269',\n",
       " 'target_270',\n",
       " 'target_271',\n",
       " 'target_272',\n",
       " 'target_273',\n",
       " 'target_274',\n",
       " 'target_275',\n",
       " 'target_276',\n",
       " 'target_277',\n",
       " 'target_278',\n",
       " 'target_279',\n",
       " 'target_280',\n",
       " 'target_281',\n",
       " 'target_282',\n",
       " 'target_283',\n",
       " 'target_284',\n",
       " 'target_285',\n",
       " 'target_286',\n",
       " 'target_287',\n",
       " 'target_288',\n",
       " 'target_289',\n",
       " 'target_290',\n",
       " 'target_291',\n",
       " 'target_292',\n",
       " 'target_293',\n",
       " 'target_294',\n",
       " 'target_295',\n",
       " 'target_296',\n",
       " 'target_297',\n",
       " 'target_298',\n",
       " 'target_299',\n",
       " 'target_300',\n",
       " 'target_301',\n",
       " 'target_302',\n",
       " 'target_303',\n",
       " 'target_304',\n",
       " 'target_305',\n",
       " 'target_306',\n",
       " 'target_307',\n",
       " 'target_308',\n",
       " 'target_309',\n",
       " 'target_310',\n",
       " 'target_311',\n",
       " 'target_312',\n",
       " 'target_313',\n",
       " 'target_314',\n",
       " 'target_315',\n",
       " 'target_316',\n",
       " 'target_317',\n",
       " 'target_318',\n",
       " 'target_319',\n",
       " 'target_320',\n",
       " 'target_321',\n",
       " 'target_322',\n",
       " 'target_323',\n",
       " 'target_324',\n",
       " 'target_325',\n",
       " 'target_326',\n",
       " 'target_327',\n",
       " 'target_328',\n",
       " 'target_329',\n",
       " 'target_330',\n",
       " 'target_331',\n",
       " 'target_332',\n",
       " 'target_333',\n",
       " 'target_334',\n",
       " 'target_335',\n",
       " 'target_336',\n",
       " 'target_337',\n",
       " 'target_338',\n",
       " 'target_339',\n",
       " 'target_340',\n",
       " 'target_341',\n",
       " 'target_342',\n",
       " 'target_343',\n",
       " 'target_344',\n",
       " 'target_345',\n",
       " 'target_346',\n",
       " 'target_347',\n",
       " 'target_348',\n",
       " 'target_349',\n",
       " 'target_350',\n",
       " 'target_351',\n",
       " 'target_352',\n",
       " 'target_353',\n",
       " 'target_354',\n",
       " 'target_355',\n",
       " 'target_356',\n",
       " 'target_357',\n",
       " 'target_358',\n",
       " 'target_359',\n",
       " 'target_360',\n",
       " 'target_361',\n",
       " 'target_362',\n",
       " 'target_363',\n",
       " 'target_364',\n",
       " 'target_365',\n",
       " 'target_366',\n",
       " 'target_367',\n",
       " 'target_368',\n",
       " 'target_369',\n",
       " 'target_370',\n",
       " 'target_371',\n",
       " 'target_372',\n",
       " 'target_373',\n",
       " 'target_374',\n",
       " 'target_375',\n",
       " 'target_376',\n",
       " 'target_377',\n",
       " 'target_378',\n",
       " 'target_379',\n",
       " 'target_380',\n",
       " 'target_381',\n",
       " 'target_382',\n",
       " 'target_383',\n",
       " 'target_384',\n",
       " 'target_385',\n",
       " 'target_386',\n",
       " 'target_387',\n",
       " 'target_388',\n",
       " 'target_389',\n",
       " 'target_390',\n",
       " 'target_391',\n",
       " 'target_392',\n",
       " 'target_393',\n",
       " 'target_394',\n",
       " 'target_395',\n",
       " 'target_396',\n",
       " 'target_397',\n",
       " 'target_398',\n",
       " 'target_399',\n",
       " 'target_400',\n",
       " 'target_401',\n",
       " 'target_402',\n",
       " 'target_403',\n",
       " 'target_404',\n",
       " 'target_405',\n",
       " 'target_406',\n",
       " 'target_407',\n",
       " 'target_408',\n",
       " 'target_409',\n",
       " 'target_410',\n",
       " 'target_411',\n",
       " 'target_412',\n",
       " 'target_413',\n",
       " 'target_414',\n",
       " 'target_415',\n",
       " 'target_416',\n",
       " 'target_417',\n",
       " 'target_418',\n",
       " 'target_419',\n",
       " 'target_420',\n",
       " 'target_421',\n",
       " 'target_422',\n",
       " 'target_423']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.0059485 , -0.00285132, -0.0046752 , ...,  0.03823403,\n",
       "                nan,  0.02730989],\n",
       "       [ 0.00578281, -0.02411763, -0.00705199, ...,  0.02502068,\n",
       "         0.00354846,  0.02094043],\n",
       "       [ 0.00104825,  0.02383639, -0.00893406, ...,  0.00483537,\n",
       "        -0.00907498,  0.00170587],\n",
       "       ...,\n",
       "       [-0.00229414,  0.01289763,  0.00997804, ..., -0.01330409,\n",
       "        -0.00552677, -0.12768791],\n",
       "       [        nan,         nan,         nan, ..., -0.00692833,\n",
       "         0.00680538, -0.01218726],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "         0.01256203,         nan]], shape=(1917, 424))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_values,target_cols = featureTarget.prepare_targets(train_labels_df)\n",
    "display(target_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "53c45741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature preparation failed: 'id'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[167]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_features, test_features = \u001b[43mfeatureEngineer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprepare_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_df_process\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 173\u001b[39m, in \u001b[36mFeatureEngineer.prepare_features\u001b[39m\u001b[34m(self, train_df, test_df)\u001b[39m\n\u001b[32m    161\u001b[39m combined_data = pd.concat([\n\u001b[32m    162\u001b[39m     train_df[\u001b[38;5;28mlist\u001b[39m(common_cols)],\n\u001b[32m    163\u001b[39m     test_df[\u001b[38;5;28mlist\u001b[39m(common_cols)]\n\u001b[32m    164\u001b[39m ], axis=\u001b[32m0\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    166\u001b[39m combined_data = train_df.merge(\n\u001b[32m    167\u001b[39m     test_df,\n\u001b[32m    168\u001b[39m     on=\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    169\u001b[39m     how=\u001b[33m'\u001b[39m\u001b[33minner\u001b[39m\u001b[33m'\u001b[39m,   \u001b[38;5;66;03m# ou 'left'\u001b[39;00m\n\u001b[32m    170\u001b[39m     suffixes=(\u001b[33m'\u001b[39m\u001b[33m_t2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_t1\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    171\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m combined_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_lag_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# Add rolling features\u001b[39;00m\n\u001b[32m    176\u001b[39m combined_data = \u001b[38;5;28mself\u001b[39m.add_rolling_features(combined_data, windows=[\u001b[32m5\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m15\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 128\u001b[39m, in \u001b[36mFeatureEngineer.add_lag_features\u001b[39m\u001b[34m(self, df, lags, date_col)\u001b[39m\n\u001b[32m    126\u001b[39m df = df.sort_values(date_col)\n\u001b[32m    127\u001b[39m cols = \u001b[38;5;28mset\u001b[39m(df.columns)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[43mcols\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m cols.remove(\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols:\n",
      "\u001b[31mKeyError\u001b[39m: 'id'"
     ]
    }
   ],
   "source": [
    "train_features, test_features = featureEngineer.prepare_features(train_df_process,test_df_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3c491869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interest</th>\n",
       "      <th>id</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>sprice</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>interest_lag1</th>\n",
       "      <th>...</th>\n",
       "      <th>open_lag5_rollmin5</th>\n",
       "      <th>open_lag5_rollmax5</th>\n",
       "      <th>open_lag5_rollmean10</th>\n",
       "      <th>open_lag5_rollstd10</th>\n",
       "      <th>open_lag5_rollmin10</th>\n",
       "      <th>open_lag5_rollmax10</th>\n",
       "      <th>open_lag5_rollmean15</th>\n",
       "      <th>open_lag5_rollstd15</th>\n",
       "      <th>open_lag5_rollmin15</th>\n",
       "      <th>open_lag5_rollmax15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1768.0</td>\n",
       "      <td>FX_AUDCAD</td>\n",
       "      <td>24.5242</td>\n",
       "      <td>23.9998</td>\n",
       "      <td>23.8900</td>\n",
       "      <td>2464147.0</td>\n",
       "      <td>4730.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979601</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.00810</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.008100</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1768.0</td>\n",
       "      <td>FX_AUDJPY</td>\n",
       "      <td>24.5242</td>\n",
       "      <td>23.9998</td>\n",
       "      <td>23.8900</td>\n",
       "      <td>2464147.0</td>\n",
       "      <td>4730.0</td>\n",
       "      <td>0</td>\n",
       "      <td>87.933498</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.00810</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.008100</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1768.0</td>\n",
       "      <td>FX_AUDNZD</td>\n",
       "      <td>24.5242</td>\n",
       "      <td>23.9998</td>\n",
       "      <td>23.8900</td>\n",
       "      <td>2464147.0</td>\n",
       "      <td>4730.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.103011</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.00810</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.008100</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1768.0</td>\n",
       "      <td>FX_AUDUSD</td>\n",
       "      <td>24.5242</td>\n",
       "      <td>23.9998</td>\n",
       "      <td>23.8900</td>\n",
       "      <td>2464147.0</td>\n",
       "      <td>4730.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.783393</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.00810</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.008100</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1768.0</td>\n",
       "      <td>FX_CADCHF</td>\n",
       "      <td>24.5242</td>\n",
       "      <td>23.9998</td>\n",
       "      <td>23.8900</td>\n",
       "      <td>2464147.0</td>\n",
       "      <td>4730.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.776874</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.00810</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.008100</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280537</th>\n",
       "      <td>9665.0</td>\n",
       "      <td>US_Stock_EMB</td>\n",
       "      <td>90.8473</td>\n",
       "      <td>90.7680</td>\n",
       "      <td>90.3765</td>\n",
       "      <td>8001299.0</td>\n",
       "      <td>14730.0</td>\n",
       "      <td>1871</td>\n",
       "      <td>90.440900</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.6381</td>\n",
       "      <td>90.0048</td>\n",
       "      <td>89.89879</td>\n",
       "      <td>0.169768</td>\n",
       "      <td>89.6381</td>\n",
       "      <td>90.1139</td>\n",
       "      <td>89.976427</td>\n",
       "      <td>0.180164</td>\n",
       "      <td>89.6381</td>\n",
       "      <td>90.1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280538</th>\n",
       "      <td>9665.0</td>\n",
       "      <td>US_Stock_ENB</td>\n",
       "      <td>43.5751</td>\n",
       "      <td>42.9447</td>\n",
       "      <td>42.8167</td>\n",
       "      <td>1884488.0</td>\n",
       "      <td>14730.0</td>\n",
       "      <td>1871</td>\n",
       "      <td>43.565300</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.9499</td>\n",
       "      <td>42.8758</td>\n",
       "      <td>42.10457</td>\n",
       "      <td>0.350060</td>\n",
       "      <td>41.6643</td>\n",
       "      <td>42.8758</td>\n",
       "      <td>41.878680</td>\n",
       "      <td>0.490887</td>\n",
       "      <td>40.9108</td>\n",
       "      <td>42.8758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280539</th>\n",
       "      <td>9665.0</td>\n",
       "      <td>US_Stock_EOG</td>\n",
       "      <td>124.3516</td>\n",
       "      <td>122.8256</td>\n",
       "      <td>121.8891</td>\n",
       "      <td>4074876.0</td>\n",
       "      <td>14730.0</td>\n",
       "      <td>1871</td>\n",
       "      <td>123.172400</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119.9024</td>\n",
       "      <td>123.5737</td>\n",
       "      <td>122.43964</td>\n",
       "      <td>1.710212</td>\n",
       "      <td>119.9024</td>\n",
       "      <td>125.7885</td>\n",
       "      <td>122.961360</td>\n",
       "      <td>1.998596</td>\n",
       "      <td>119.9024</td>\n",
       "      <td>125.7885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280540</th>\n",
       "      <td>9665.0</td>\n",
       "      <td>US_Stock_EWJ</td>\n",
       "      <td>71.3400</td>\n",
       "      <td>70.7700</td>\n",
       "      <td>70.7600</td>\n",
       "      <td>2640384.0</td>\n",
       "      <td>14730.0</td>\n",
       "      <td>1871</td>\n",
       "      <td>71.320000</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.3700</td>\n",
       "      <td>70.6700</td>\n",
       "      <td>69.74700</td>\n",
       "      <td>0.737052</td>\n",
       "      <td>68.4800</td>\n",
       "      <td>70.6700</td>\n",
       "      <td>69.608667</td>\n",
       "      <td>0.704210</td>\n",
       "      <td>68.4800</td>\n",
       "      <td>70.6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280483</th>\n",
       "      <td>9665.0</td>\n",
       "      <td>FX_GBPAUD</td>\n",
       "      <td>71.3400</td>\n",
       "      <td>70.7700</td>\n",
       "      <td>70.7600</td>\n",
       "      <td>2640384.0</td>\n",
       "      <td>14730.0</td>\n",
       "      <td>1871</td>\n",
       "      <td>2.057147</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.3700</td>\n",
       "      <td>70.6700</td>\n",
       "      <td>69.74700</td>\n",
       "      <td>0.737052</td>\n",
       "      <td>68.4800</td>\n",
       "      <td>70.6700</td>\n",
       "      <td>69.608667</td>\n",
       "      <td>0.704210</td>\n",
       "      <td>68.4800</td>\n",
       "      <td>70.6700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274131 rows × 548 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        interest            id      high      open       low     volume  \\\n",
       "0         1768.0     FX_AUDCAD   24.5242   23.9998   23.8900  2464147.0   \n",
       "2         1768.0     FX_AUDJPY   24.5242   23.9998   23.8900  2464147.0   \n",
       "3         1768.0     FX_AUDNZD   24.5242   23.9998   23.8900  2464147.0   \n",
       "4         1768.0     FX_AUDUSD   24.5242   23.9998   23.8900  2464147.0   \n",
       "5         1768.0     FX_CADCHF   24.5242   23.9998   23.8900  2464147.0   \n",
       "...          ...           ...       ...       ...       ...        ...   \n",
       "280537    9665.0  US_Stock_EMB   90.8473   90.7680   90.3765  8001299.0   \n",
       "280538    9665.0  US_Stock_ENB   43.5751   42.9447   42.8167  1884488.0   \n",
       "280539    9665.0  US_Stock_EOG  124.3516  122.8256  121.8891  4074876.0   \n",
       "280540    9665.0  US_Stock_EWJ   71.3400   70.7700   70.7600  2640384.0   \n",
       "280483    9665.0     FX_GBPAUD   71.3400   70.7700   70.7600  2640384.0   \n",
       "\n",
       "         sprice  date       close  interest_lag1  ...  open_lag5_rollmin5  \\\n",
       "0        4730.0     0    0.979601         1768.0  ...            147.0081   \n",
       "2        4730.0     0   87.933498         1768.0  ...            147.0081   \n",
       "3        4730.0     0    1.103011         1768.0  ...            147.0081   \n",
       "4        4730.0     0    0.783393         1768.0  ...            147.0081   \n",
       "5        4730.0     0    0.776874         1768.0  ...            147.0081   \n",
       "...         ...   ...         ...            ...  ...                 ...   \n",
       "280537  14730.0  1871   90.440900         9158.0  ...             89.6381   \n",
       "280538  14730.0  1871   43.565300         9158.0  ...             41.9499   \n",
       "280539  14730.0  1871  123.172400         9158.0  ...            119.9024   \n",
       "280540  14730.0  1871   71.320000         9158.0  ...             69.3700   \n",
       "280483  14730.0  1871    2.057147         9158.0  ...             69.3700   \n",
       "\n",
       "        open_lag5_rollmax5  open_lag5_rollmean10  open_lag5_rollstd10  \\\n",
       "0                 147.0081             147.00810             0.274145   \n",
       "2                 147.0081             147.00810             0.274145   \n",
       "3                 147.0081             147.00810             0.274145   \n",
       "4                 147.0081             147.00810             0.274145   \n",
       "5                 147.0081             147.00810             0.274145   \n",
       "...                    ...                   ...                  ...   \n",
       "280537             90.0048              89.89879             0.169768   \n",
       "280538             42.8758              42.10457             0.350060   \n",
       "280539            123.5737             122.43964             1.710212   \n",
       "280540             70.6700              69.74700             0.737052   \n",
       "280483             70.6700              69.74700             0.737052   \n",
       "\n",
       "        open_lag5_rollmin10  open_lag5_rollmax10  open_lag5_rollmean15  \\\n",
       "0                  147.0081             147.0081            147.008100   \n",
       "2                  147.0081             147.0081            147.008100   \n",
       "3                  147.0081             147.0081            147.008100   \n",
       "4                  147.0081             147.0081            147.008100   \n",
       "5                  147.0081             147.0081            147.008100   \n",
       "...                     ...                  ...                   ...   \n",
       "280537              89.6381              90.1139             89.976427   \n",
       "280538              41.6643              42.8758             41.878680   \n",
       "280539             119.9024             125.7885            122.961360   \n",
       "280540              68.4800              70.6700             69.608667   \n",
       "280483              68.4800              70.6700             69.608667   \n",
       "\n",
       "        open_lag5_rollstd15  open_lag5_rollmin15  open_lag5_rollmax15  \n",
       "0                  0.274145             147.0081             147.0081  \n",
       "2                  0.274145             147.0081             147.0081  \n",
       "3                  0.274145             147.0081             147.0081  \n",
       "4                  0.274145             147.0081             147.0081  \n",
       "5                  0.274145             147.0081             147.0081  \n",
       "...                     ...                  ...                  ...  \n",
       "280537             0.180164              89.6381              90.1733  \n",
       "280538             0.490887              40.9108              42.8758  \n",
       "280539             1.998596             119.9024             125.7885  \n",
       "280540             0.704210              68.4800              70.6700  \n",
       "280483             0.704210              68.4800              70.6700  \n",
       "\n",
       "[274131 rows x 548 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>lag</th>\n",
       "      <th>price_1</th>\n",
       "      <th>price_2</th>\n",
       "      <th>is_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target_0</td>\n",
       "      <td>1</td>\n",
       "      <td>US_Stock_VT_adj_close</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>target_1</td>\n",
       "      <td>1</td>\n",
       "      <td>LME_PB_Close</td>\n",
       "      <td>US_Stock_VT_adj_close</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>target_2</td>\n",
       "      <td>1</td>\n",
       "      <td>LME_CA_Close</td>\n",
       "      <td>LME_ZS_Close</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>target_3</td>\n",
       "      <td>1</td>\n",
       "      <td>LME_AH_Close</td>\n",
       "      <td>LME_ZS_Close</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>target_4</td>\n",
       "      <td>1</td>\n",
       "      <td>LME_AH_Close</td>\n",
       "      <td>JPX_Gold_Standard_Futures_Close</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>target_419</td>\n",
       "      <td>4</td>\n",
       "      <td>FX_NOKUSD</td>\n",
       "      <td>LME_AH_Close</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>target_420</td>\n",
       "      <td>4</td>\n",
       "      <td>JPX_Gold_Standard_Futures_Close</td>\n",
       "      <td>US_Stock_RY_adj_close</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>target_421</td>\n",
       "      <td>4</td>\n",
       "      <td>US_Stock_EWT_adj_close</td>\n",
       "      <td>LME_AH_Close</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>target_422</td>\n",
       "      <td>4</td>\n",
       "      <td>JPX_Platinum_Standard_Futures_Close</td>\n",
       "      <td>FX_NOKCHF</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>target_423</td>\n",
       "      <td>4</td>\n",
       "      <td>LME_CA_Close</td>\n",
       "      <td>US_Stock_CCJ_adj_close</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target  lag                              price_1  \\\n",
       "0      target_0    1                US_Stock_VT_adj_close   \n",
       "1      target_1    1                         LME_PB_Close   \n",
       "2      target_2    1                         LME_CA_Close   \n",
       "3      target_3    1                         LME_AH_Close   \n",
       "4      target_4    1                         LME_AH_Close   \n",
       "..          ...  ...                                  ...   \n",
       "419  target_419    4                            FX_NOKUSD   \n",
       "420  target_420    4      JPX_Gold_Standard_Futures_Close   \n",
       "421  target_421    4               US_Stock_EWT_adj_close   \n",
       "422  target_422    4  JPX_Platinum_Standard_Futures_Close   \n",
       "423  target_423    4                         LME_CA_Close   \n",
       "\n",
       "                             price_2  is_pair  \n",
       "0                               None    False  \n",
       "1              US_Stock_VT_adj_close     True  \n",
       "2                       LME_ZS_Close     True  \n",
       "3                       LME_ZS_Close     True  \n",
       "4    JPX_Gold_Standard_Futures_Close     True  \n",
       "..                               ...      ...  \n",
       "419                     LME_AH_Close     True  \n",
       "420            US_Stock_RY_adj_close     True  \n",
       "421                     LME_AH_Close     True  \n",
       "422                        FX_NOKCHF     True  \n",
       "423           US_Stock_CCJ_adj_close     True  \n",
       "\n",
       "[424 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_features)\n",
    "target_info = featureTarget.prepare_targets_info(target_pairs_df)\n",
    "display(target_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "32c8ad41",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[178]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m fx_nokusd_data = train_features[\u001b[43mtrain_features\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[33m'\u001b[39m\u001b[33mUS_Stock_CCJ\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      2\u001b[39m display(fx_nokusd_data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'id'"
     ]
    }
   ],
   "source": [
    "fx_nokusd_data = train_features[train_features['id'] == 'US_Stock_CCJ']\n",
    "display(fx_nokusd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35863459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ee93b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "  \"\"\"LSTM model for time series prediction\"\"\"\n",
    "  def __init__(self,input_size,hidden_size=128,num_layers=2, dropout=0.2):\n",
    "    super().__init__()\n",
    "\n",
    "    # store parameters\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # RNN Layer (notation: LSTM \\in RNN)\n",
    "    self.lstm = nn.LSTM(\n",
    "      input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "            )\n",
    "    \n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    # linear layer for output\n",
    "    self.fc = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    lstm_out, _ = self.lstm(x)\n",
    "    last_output = lstm_out[:, -1, :]\n",
    "    out = self.dropout(last_output)\n",
    "    out = self.fc(out)\n",
    "    return out\n",
    "  \n",
    "\n",
    "class GRUModel(nn.Module):\n",
    "    \"\"\"GRU model for time series prediction\"\"\"\n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=2, dropout=0.2):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        gru_out, _ = self.gru(x)\n",
    "        last_output = gru_out[:, -1, :]\n",
    "        out = self.dropout(last_output)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98359ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "db843543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'US_Stock_VT'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interest</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>sprice</th>\n",
       "      <th>close</th>\n",
       "      <th>interest_lag1</th>\n",
       "      <th>interest_lag2</th>\n",
       "      <th>interest_lag3</th>\n",
       "      <th>...</th>\n",
       "      <th>open_lag5_rollmin5</th>\n",
       "      <th>open_lag5_rollmax5</th>\n",
       "      <th>open_lag5_rollmean10</th>\n",
       "      <th>open_lag5_rollstd10</th>\n",
       "      <th>open_lag5_rollmin10</th>\n",
       "      <th>open_lag5_rollmax10</th>\n",
       "      <th>open_lag5_rollmean15</th>\n",
       "      <th>open_lag5_rollstd15</th>\n",
       "      <th>open_lag5_rollmin15</th>\n",
       "      <th>open_lag5_rollmax15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1768.0</td>\n",
       "      <td>63.9271</td>\n",
       "      <td>63.6198</td>\n",
       "      <td>63.5857</td>\n",
       "      <td>1267705.0</td>\n",
       "      <td>4730.0</td>\n",
       "      <td>63.9271</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>128380.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.00810</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.008100</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>1768.0</td>\n",
       "      <td>64.3793</td>\n",
       "      <td>64.0039</td>\n",
       "      <td>64.0039</td>\n",
       "      <td>768549.0</td>\n",
       "      <td>4730.0</td>\n",
       "      <td>64.3623</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>128380.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.00810</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.008100</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1323.0</td>\n",
       "      <td>64.8316</td>\n",
       "      <td>64.6610</td>\n",
       "      <td>64.6439</td>\n",
       "      <td>819369.0</td>\n",
       "      <td>3423.0</td>\n",
       "      <td>64.7463</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>128380.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.00810</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.008100</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>8635.0</td>\n",
       "      <td>65.1389</td>\n",
       "      <td>64.9341</td>\n",
       "      <td>64.8231</td>\n",
       "      <td>925118.0</td>\n",
       "      <td>204.8</td>\n",
       "      <td>65.1218</td>\n",
       "      <td>7391.0</td>\n",
       "      <td>128380.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.00810</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.008100</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>8635.0</td>\n",
       "      <td>65.2071</td>\n",
       "      <td>65.0621</td>\n",
       "      <td>64.9981</td>\n",
       "      <td>723160.0</td>\n",
       "      <td>204.8</td>\n",
       "      <td>65.1901</td>\n",
       "      <td>2026.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>...</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.00810</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.008100</td>\n",
       "      <td>0.274145</td>\n",
       "      <td>147.0081</td>\n",
       "      <td>147.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280310</th>\n",
       "      <td>45881.0</td>\n",
       "      <td>117.9944</td>\n",
       "      <td>117.9047</td>\n",
       "      <td>117.0176</td>\n",
       "      <td>1690125.0</td>\n",
       "      <td>14300.0</td>\n",
       "      <td>117.4063</td>\n",
       "      <td>46412.0</td>\n",
       "      <td>46412.0</td>\n",
       "      <td>47065.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>116.4594</td>\n",
       "      <td>116.64577</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>118.0342</td>\n",
       "      <td>117.307947</td>\n",
       "      <td>1.205360</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>118.8117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267398</th>\n",
       "      <td>2081.0</td>\n",
       "      <td>117.9944</td>\n",
       "      <td>117.9047</td>\n",
       "      <td>117.0176</td>\n",
       "      <td>1690125.0</td>\n",
       "      <td>346.9</td>\n",
       "      <td>117.4063</td>\n",
       "      <td>2081.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>2122.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>116.4594</td>\n",
       "      <td>116.41353</td>\n",
       "      <td>0.771000</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>118.0342</td>\n",
       "      <td>117.141153</td>\n",
       "      <td>1.243569</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>118.8117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267541</th>\n",
       "      <td>9665.0</td>\n",
       "      <td>119.0492</td>\n",
       "      <td>117.6455</td>\n",
       "      <td>117.3764</td>\n",
       "      <td>1170651.0</td>\n",
       "      <td>14631.0</td>\n",
       "      <td>118.3731</td>\n",
       "      <td>9665.0</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>117.1372</td>\n",
       "      <td>116.42051</td>\n",
       "      <td>0.777863</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>118.0342</td>\n",
       "      <td>117.039487</td>\n",
       "      <td>1.170527</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>118.8117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280454</th>\n",
       "      <td>3490.0</td>\n",
       "      <td>119.0492</td>\n",
       "      <td>117.6455</td>\n",
       "      <td>117.3764</td>\n",
       "      <td>1170651.0</td>\n",
       "      <td>14730.0</td>\n",
       "      <td>118.3731</td>\n",
       "      <td>3490.0</td>\n",
       "      <td>3311.0</td>\n",
       "      <td>3311.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>117.1372</td>\n",
       "      <td>116.19724</td>\n",
       "      <td>0.550386</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>117.1372</td>\n",
       "      <td>116.838807</td>\n",
       "      <td>1.100962</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>118.8117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267684</th>\n",
       "      <td>9665.0</td>\n",
       "      <td>118.4628</td>\n",
       "      <td>117.2967</td>\n",
       "      <td>117.1571</td>\n",
       "      <td>1589470.0</td>\n",
       "      <td>14730.0</td>\n",
       "      <td>117.8648</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>9158.0</td>\n",
       "      <td>8721.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>117.9047</td>\n",
       "      <td>116.39659</td>\n",
       "      <td>0.757372</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>117.9047</td>\n",
       "      <td>116.788307</td>\n",
       "      <td>1.026185</td>\n",
       "      <td>115.7118</td>\n",
       "      <td>118.8117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1916 rows × 546 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        interest      high      open       low     volume   sprice     close  \\\n",
       "131       1768.0   63.9271   63.6198   63.5857  1267705.0   4730.0   63.9271   \n",
       "274       1768.0   64.3793   64.0039   64.0039   768549.0   4730.0   64.3623   \n",
       "417       1323.0   64.8316   64.6610   64.6439   819369.0   3423.0   64.7463   \n",
       "560       8635.0   65.1389   64.9341   64.8231   925118.0    204.8   65.1218   \n",
       "703       8635.0   65.2071   65.0621   64.9981   723160.0    204.8   65.1901   \n",
       "...          ...       ...       ...       ...        ...      ...       ...   \n",
       "280310   45881.0  117.9944  117.9047  117.0176  1690125.0  14300.0  117.4063   \n",
       "267398    2081.0  117.9944  117.9047  117.0176  1690125.0    346.9  117.4063   \n",
       "267541    9665.0  119.0492  117.6455  117.3764  1170651.0  14631.0  118.3731   \n",
       "280454    3490.0  119.0492  117.6455  117.3764  1170651.0  14730.0  118.3731   \n",
       "267684    9665.0  118.4628  117.2967  117.1571  1589470.0  14730.0  117.8648   \n",
       "\n",
       "        interest_lag1  interest_lag2  interest_lag3  ...  open_lag5_rollmin5  \\\n",
       "131            1768.0       128380.0         1768.0  ...            147.0081   \n",
       "274            1768.0       128380.0         1768.0  ...            147.0081   \n",
       "417            1768.0       128380.0         1768.0  ...            147.0081   \n",
       "560            7391.0       128380.0         1768.0  ...            147.0081   \n",
       "703            2026.0         1768.0         1768.0  ...            147.0081   \n",
       "...               ...            ...            ...  ...                 ...   \n",
       "280310        46412.0        46412.0        47065.0  ...            115.7118   \n",
       "267398         2081.0         2122.0         2122.0  ...            115.7118   \n",
       "267541         9665.0         9158.0         9158.0  ...            115.7118   \n",
       "280454         3490.0         3311.0         3311.0  ...            115.7118   \n",
       "267684         9158.0         9158.0         8721.0  ...            115.7118   \n",
       "\n",
       "        open_lag5_rollmax5  open_lag5_rollmean10  open_lag5_rollstd10  \\\n",
       "131               147.0081             147.00810             0.274145   \n",
       "274               147.0081             147.00810             0.274145   \n",
       "417               147.0081             147.00810             0.274145   \n",
       "560               147.0081             147.00810             0.274145   \n",
       "703               147.0081             147.00810             0.274145   \n",
       "...                    ...                   ...                  ...   \n",
       "280310            116.4594             116.64577             0.878431   \n",
       "267398            116.4594             116.41353             0.771000   \n",
       "267541            117.1372             116.42051             0.777863   \n",
       "280454            117.1372             116.19724             0.550386   \n",
       "267684            117.9047             116.39659             0.757372   \n",
       "\n",
       "        open_lag5_rollmin10  open_lag5_rollmax10  open_lag5_rollmean15  \\\n",
       "131                147.0081             147.0081            147.008100   \n",
       "274                147.0081             147.0081            147.008100   \n",
       "417                147.0081             147.0081            147.008100   \n",
       "560                147.0081             147.0081            147.008100   \n",
       "703                147.0081             147.0081            147.008100   \n",
       "...                     ...                  ...                   ...   \n",
       "280310             115.7118             118.0342            117.307947   \n",
       "267398             115.7118             118.0342            117.141153   \n",
       "267541             115.7118             118.0342            117.039487   \n",
       "280454             115.7118             117.1372            116.838807   \n",
       "267684             115.7118             117.9047            116.788307   \n",
       "\n",
       "        open_lag5_rollstd15  open_lag5_rollmin15  open_lag5_rollmax15  \n",
       "131                0.274145             147.0081             147.0081  \n",
       "274                0.274145             147.0081             147.0081  \n",
       "417                0.274145             147.0081             147.0081  \n",
       "560                0.274145             147.0081             147.0081  \n",
       "703                0.274145             147.0081             147.0081  \n",
       "...                     ...                  ...                  ...  \n",
       "280310             1.205360             115.7118             118.8117  \n",
       "267398             1.243569             115.7118             118.8117  \n",
       "267541             1.170527             115.7118             118.8117  \n",
       "280454             1.100962             115.7118             118.8117  \n",
       "267684             1.026185             115.7118             118.8117  \n",
       "\n",
       "[1916 rows x 546 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train target values\n",
    "def convert_to_colname(colname:str)-> str:\n",
    "    if colname is None:\n",
    "        return None\n",
    "    if colname.startswith(\"FX_\"):\n",
    "        return colname\n",
    "    colname = colname.replace(\"_adj\",\"\")\n",
    "    colname = colname.rsplit('_', 1)[0]\n",
    "    return colname\n",
    "\n",
    "indexe_target:int = 0\n",
    "target_name = target_info.loc[indexe_target,'target']\n",
    "target_col1 = convert_to_colname(target_info.loc[indexe_target,'price_1'])\n",
    "\n",
    "display(target_col1)  \n",
    "target_col2 = convert_to_colname(target_info.loc[indexe_target,'price_2'])\n",
    "\n",
    "display(target_col2)  \n",
    "\n",
    "def train_features_build(target_col1,target_col2):\n",
    " # Filter for the two targets\n",
    "    if target_col2 is not None:\n",
    "        df_target2 = train_features[train_features['id'] == target_col2]\n",
    "        df_target1 = train_features[train_features['id'] == target_col1]\n",
    "        \n",
    "        # Concatenate the two DataFrames side by side (axis=1)\n",
    "        result = df_target2.merge(\n",
    "    df_target1,\n",
    "    on='date',\n",
    "    how='inner',   # ou 'left'\n",
    "    suffixes=('_t2', '_t1')\n",
    ")\n",
    "        result = result.drop(['id', 'date'], axis=1, errors='ignore')\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "    \n",
    "        df_target1 = train_features[train_features['id'] == target_col1]\n",
    "        # Concatenate the two DataFrames side by side (axis=1)\n",
    "        result = df_target1\n",
    "        result = result.drop(['id', 'date'], axis=1, errors='ignore')\n",
    "        \n",
    "        return result\n",
    "\n",
    "display(train_features_build(target_col1,target_col2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c125c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for time series data\"\"\"\n",
    "    def __init__(self, X, y, sequence_length=10):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.sequence_length\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.X[idx:idx + self.sequence_length],\n",
    "            self.y[idx + self.sequence_length]\n",
    "        )\n",
    "    \n",
    "def prepare_data(self, X, y, sequence_length=10, batch_size=32):\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Create dataset and dataloader\n",
    "        dataset = TimeSeriesDataset(X_scaled, y, sequence_length)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        return dataloader, scaler\n",
    "        \n",
    "\n",
    "def train_models_for_target(train_features:pd.DataFrame,\n",
    "                target_values:np.ndarray,\n",
    "                target_col1:str,\n",
    "                target_col2:str,\n",
    "                model_type:str='LSTM',\n",
    "                num_epochs:int=10,\n",
    "                batch_size:int=32,\n",
    "                learning_rate:float=0.001):\n",
    "    \n",
    "    valid_indices = ~np.isnan(target_values)\n",
    "    X_valid = train_features_build(target_col1,target_col2)[valid_indices]\n",
    "    y_valid = target_values[valid_indices]\n",
    "\n",
    "\n",
    "    # Simple train/validation split (last 20% for validation)\n",
    "    split_idx = int(len(X_valid) * 0.8)\n",
    "    X_train = X_valid[:split_idx]\n",
    "    y_train = y_valid[:split_idx]\n",
    "    \n",
    "    X_val = X_valid[split_idx:]\n",
    "    y_val = y_valid[split_idx:]\n",
    "    # Prepare data\n",
    "    train_loader, scaler = prepare_data(\n",
    "                    X_train, y_train, \n",
    "                    10, batch_size\n",
    "                )\n",
    "    \n",
    "    # Initialize model\n",
    "    input_size = X_train.shape[1]\n",
    "    if model_type == 'LSTM':\n",
    "        model = LSTMModel(input_size)\n",
    "    elif model_type == 'GRU':\n",
    "        model = GRUModel(input_size)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose 'LSTM' or 'GRU'.\")\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs.squeeze(), batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dd143c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target 1/1: target_0\n",
      "\n",
      "Target target_0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Item wrong length 1917 instead of 1916.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_13632\\2346894170.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m     price1 = convert_to_colname(target_info.loc[target_idx,\u001b[33m'price_1'\u001b[39m])\n\u001b[32m      8\u001b[39m     price2 = convert_to_colname(target_info.loc[target_idx,\u001b[33m'price_2'\u001b[39m])\n\u001b[32m      9\u001b[39m     y = target_values[:, target_idx]\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Train models for this target\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     target_models = train_models_for_target(target_name, y, price1, price2)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_13632\\1288845195.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(train_features, target_values, target_col1, target_col2, model_type, num_epochs, batch_size, learning_rate)\u001b[39m\n\u001b[32m     38\u001b[39m                 batch_size:int=\u001b[32m32\u001b[39m,\n\u001b[32m     39\u001b[39m                 learning_rate:float=\u001b[32m0.001\u001b[39m):\n\u001b[32m     40\u001b[39m \n\u001b[32m     41\u001b[39m     valid_indices = ~np.isnan(target_values)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     X_valid = train_features_build(target_col1,target_col2)[valid_indices]\n\u001b[32m     43\u001b[39m     y_valid = target_values[valid_indices]\n\u001b[32m     44\u001b[39m \n\u001b[32m     45\u001b[39m \n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.where(key)\n\u001b[32m   4101\u001b[39m \n\u001b[32m   4102\u001b[39m         \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[32m   4103\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m com.is_bool_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m4104\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self._getitem_bool_array(key)\n\u001b[32m   4105\u001b[39m \n\u001b[32m   4106\u001b[39m         \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[32m   4107\u001b[39m         \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4150\u001b[39m                 UserWarning,\n\u001b[32m   4151\u001b[39m                 stacklevel=find_stack_level(),\n\u001b[32m   4152\u001b[39m             )\n\u001b[32m   4153\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m len(key) != len(self.index):\n\u001b[32m-> \u001b[39m\u001b[32m4154\u001b[39m             raise ValueError(\n\u001b[32m   4155\u001b[39m                 f\"Item wrong length {len(key)} instead of {len(self.index)}.\"\n\u001b[32m   4156\u001b[39m             )\n\u001b[32m   4157\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: Item wrong length 1917 instead of 1916."
     ]
    }
   ],
   "source": [
    "num_targets = min(1, len(target_cols))\n",
    "selected_targets = target_cols[:num_targets]\n",
    "for target_idx, target_name in enumerate(selected_targets):\n",
    "    print(f\"\\nTarget {target_idx + 1}/{num_targets}: {target_name}\")\n",
    "    print(f\"\\nTarget {target_info.loc[target_idx,'target']}\")\n",
    "    # Get target values\n",
    "    price1 = convert_to_colname(target_info.loc[target_idx,'price_1'])\n",
    "    price2 = convert_to_colname(target_info.loc[target_idx,'price_2'])\n",
    "    y = target_values[:, target_idx]\n",
    "    # Train models for this target\n",
    "    target_models = train_models_for_target(target_name, y, price1, price2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
